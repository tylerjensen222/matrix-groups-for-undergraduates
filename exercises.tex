%==============================================================================
%  Matrix Groups for Undergraduates - Exercises
%  Initial LaTeX Commit
%==============================================================================

\documentclass[12pt]{book}

%------------------------------------------------------------------------------
%   Packages
%------------------------------------------------------------------------------
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{calc,3d}


\usepackage{amsmath,amssymb,amsthm}
\usepackage{geometry}
\geometry{margin=1in}

\usepackage{xparse}
\usepackage{xcolor}

% Define the 'exercise' environment with an optional status argument
\NewDocumentEnvironment{taggedexercise}{O{}}
{%
  % Increment the 'exercise' theorem counter manually
  \refstepcounter{exercise}%
  
  % Print the heading in the document with the optional status
  \par\noindent
  \textbf{Exercise \theexercise}%
  \if\relax\detokenize{#1}\relax
    % If no optional argument provided, do nothing
  \else
    \textbf{\ [#1]}%
  \fi
  \quad

  % Also add it to the ToC at the subsection level (you can adjust this to 'section' or 'subsubsection')
  % If you'd rather keep them out of the main ToC and make a separate "List of Exercises," 
  % you can adapt this approach using a custom list environment or the 'thmtools' package.
  \addcontentsline{toc}{subsection}{%
    Exercise \theexercise
    \if\relax\detokenize{#1}\relax
    \else
      \ [#1]%
    \fi
  }
}{%
  \par
}


%------------------------------------------------------------------------------
%   Theorem-Like Environments
%------------------------------------------------------------------------------
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]

% If you prefer a separate counter per section:
% \newtheorem{exercise}{Exercise}[section]

% Custom solution environment
\newenvironment{solution}
{%
  \par\noindent\textbf{Solution.}\quad
}
{%
  \qed\par
}

%------------------------------------------------------------------------------
%   Metadata
%------------------------------------------------------------------------------
\title{Exercises from \textit{Matrix Groups for Undergraduates} \\
       by Kristopher Tapp}
\author{Tyler Jensen | tyjensen222@gmail.com}
\date{\today}

%------------------------------------------------------------------------------
%   Document
%------------------------------------------------------------------------------
\begin{document}


%------------------------------------------------------------------------------
%   Common Macros for Matrix Groups and Lie Algebras
%------------------------------------------------------------------------------
\newcommand{\tr}[1]{\text{trace}({#1})}

\newcommand{\R}{\mathbb{R}}        % Real numbers
\newcommand{\C}{\mathbb{C}}        % Complex numbers
\newcommand{\HH}{\mathbb{H}}        % Quarternions
\newcommand{\Q}{\mathbb{Q}}        % Rational numbers
\newcommand{\Z}{\mathbb{Z}}        % Integers
\newcommand{\N}{\mathbb{N}}        % Natural numbers
\newcommand{\K}{\mathbb{K}}        % Arbitrary field

% Common matrices
\newcommand{\mattwo}[4]{%
  \begin{pmatrix}
    #1 & #2 \\
    #3 & #4
  \end{pmatrix}%
}
\newcommand{\boldmattwo}[4]{%
  \begin{pmatrix}
    \mathbf{#1} & \mathbf{#2} \\
    \mathbf{#3} & \mathbf{#4}
  \end{pmatrix}%
}



%--- General Linear, Special Linear, etc. 
\newcommand{\GL}[2]{\mathrm{GL}_{#1}(#2)}   % e.g. \GL{n}{\R} -> GL_n(\R)
\newcommand{\SL}[2]{\mathrm{SL}_{#1}(#2)}   % e.g. \SL{n}{\C} -> SL_n(\C)

%--- Orthogonal, Special Orthogonal, Symplectic
\newcommand{\Ogroup}[1]{\mathrm{O}(#1)}     % O(n)
\newcommand{\SO}[1]{\mathrm{SO}(#1)}        % SO(n)
\newcommand{\Sp}[1]{\mathrm{Sp}(#1)}        % Sp(n) symplectic group

%--- Unitary, Special Unitary
\newcommand{\U}[1]{\mathrm{U}(#1)}          % U(n)
\newcommand{\SU}[1]{\mathrm{SU}(#1)}        % SU(n)

%--- Lie algebras
\newcommand{\lie}[1]{\mathfrak{#1}}         % \lie{g} -> \mathfrak{g}
\newcommand{\so}[1]{\mathfrak{so}(#1)}     % so(n)
\newcommand{\sualg}[1]{\mathfrak{su}_{#1}}  % su(n)
\newcommand{\glalg}[1]{\mathfrak{gl}_{#1}}  % gl(n)
\newcommand{\slalg}[1]{\mathfrak{sl}_{#1}}  % sl(n)
\newcommand{\spalg}[1]{\mathfrak{sp}_{#1}}  % sp(n)

%--- Generic placeholders for a Lie algebra g and Lie group G
\newcommand{\g}{\mathfrak{g}}
\newcommand{\G}{\mathrm{G}}

%--- Overide Im and Re
\renewcommand{\Im}{\text{Im}}
\renewcommand{\Re}{\text{Re}}

\frontmatter
\maketitle
\tableofcontents

\mainmatter

%==============================================================================
\chapter{Matrices}
%==============================================================================

% Exercise 1.1
\begin{taggedexercise}[\textcolor{green}{Complete}]
Describe a natural 1-to-1 correspondence between elements of $\SO{3}$ and elements of

\[
T^1S^2 = \{ (p, v) \in \R^3 \times \R^3 : |p| = |v| = 1 \text{ and } p \perp q\}
\]

\end{taggedexercise}

\begin{solution}
Using the globe analogy from Question 1.2, fix a point $r$ to be the north pole, 
and a point $e$ that lies on the equator induced by the choice of $r$, and assert this as the arbitrary `identity'.

Next, given some $A \in \SO{3}$, identify an element in $T^1S^2$ via $A \mapsto (Ar, Av)$, 
as in first where $A$ maps the north pole $r$, and then how $A$ rotates the globe about the axis induced by $r$ and its antipodal point.
\end{solution}

% Exercise 1.2
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove equation 1.3:
  \[
  (A \cdot B)^T = B^T \cdot A^T
  \]
\end{taggedexercise}

\begin{solution}
  First, 
  \[
    \begin{aligned}
      (A \cdot B)^T_{ij} &= (A \cdot B)_{ji} \\
                         &= \sum_{k=1}^n A_{jk}B_{ki}
   \end{aligned}
  \]
   Next, 
   \[
    \begin{aligned}
      (B^T \cdot A^T)_{ij} &= \sum_{k=1}^n(B^T)_{ik}(A^T)_{kj} \\
                         &= \sum_{k=1}^n B_{ki}A_{jk} \\
                         &\stackrel{*}{=} \sum_{k=1}^n A_{jk}B_{ki}
   \end{aligned}
  \]
\end{solution}

Note the $\stackrel{*}{=}$ step uses the commutativity of multiplication, 
hence the above proof does not work when $\K = \HH$.


% Exercise 1.3
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove equation 1.4:
\[
\tr{A \cdot B} = \tr{B \cdot A}
\]
\end{taggedexercise}

\begin{solution}
  First,
  \[
    \begin{aligned}
      \tr{A \cdot B}_{ii} &= \sum_{i=1}^n \sum_{k=1}^n A_{ik}B_{ki} \\
   \end{aligned}
  \]
  Next,
  \[
    \begin{aligned}
      \tr{B \cdot A}_{ii} &= \sum_{i=1}^{n} (B \cdot A)_{ii} \\
                          &= \sum_{i=1}^n \sum_{k=1}^n B_{ik}A_{ki} \\
   \end{aligned}
  \]
  Carefully reindexing and resumming gives the result.
\end{solution}
Note that the `careful reindexing and resumming process' implies $\tr{}$ is invariant under cyclic permutation, e.x.:
\[
  \tr{A \cdot B \cdot C} = \tr{C \cdot A \cdot B}
\]

% Exercise 1.4
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Let $A, B \in M_n{\K}$. Prove that if $A \cdot B = I$ then $B \cdot A = I$.
\end{taggedexercise}

\begin{solution}
  Note that
  \[
  A \cdot B = I \iff A = B^{-1}.
  \]
  The result follows.
\end{solution}

% Exercise 1.5
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Suppose that the determinant of $A \in M_n(\HH)$ were defined as in Equation 1.5. Show for 
\[
  A = \boldmattwo{i}{j}{i}{j} \in M_n(\HH)
\]

that $\det(A) \neq 0$ but 
\[
R_A: H^2 \to H^2
\]
is not invertible.
\end{taggedexercise}

\begin{solution}
  Given the definition from Equation 1.5:
  \[
    \begin{aligned}
      \det (A) &= \det \boldmattwo{i}{j}{i}{j} \\
               &= \mathbf{i} \mathbf{j} - \mathbf{j} \mathbf{i} \\
               &= (1) - (-1) \\
               &= 2 \neq 0 \\
   \end{aligned}
  \]
  However,
  \[
  R_A((-\mathbf{i}, \mathbf{i})) = (-\mathbf{i}, \mathbf{i}) \cdot \boldmattwo{i}{j} 
                   {i}{j} = (-\mathbf{i}^2 + \mathbf{i}^2, -\mathbf{i}\mathbf{j} + \mathbf{i}\mathbf{j}) = (1 - 1, -\mathbf{k} + \mathbf{k}) = (0, 0)
  \]
  Hence, $R_A$ has a non-zero determiant, but is not invertible as the kernel is non-trivial.
  Similarly, clearly the columns of $A$ are linearly dependent.
\end{solution}

% Exercise 1.6
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Find $B \in M_2(\R)$ such that $R_B : \R^2 \to \R^2$ is a counter-clockwise rotation through an angle $\theta$.
\end{taggedexercise}

\begin{solution}
  Note that we can `represent' both $1$ and $i$ in $M_2(\R)$ via
  \[
  1 \to \mattwo{1}{0}{0}{1} = I \text{ and } i \to \mattwo{0}{1}{-1}{0}
  \]
  where the latter works since
  \[
    \mattwo{0}{1}{-1}{0}^2 = \mattwo{-1}{0}{0}{-1} = -I
  \]
  capturing the fact that $i^2 = -1$. 
  Building on this, we can represent any $a+bi \in \C$ via 
  \[
    \rho : a+bi\mapsto a \cdot I + b \cdot \mattwo{0}{1}{-1}{0} = \mattwo{a}{b}{-b}{a}.
  \]
  Next, note that the function $f_\theta(z) = ze^{i\theta}$ rotates elements counter-clockwise in $\C$ by an angle $\theta$. 
  To see this, letting $z=re^{i\varphi}$,
  \[f_\theta(z) = ze^{i\theta} = re^{i\varphi}e^{i\theta} = re^{i(\varphi + \theta)}.\]
  Applying $\rho$ gives
  \[
  \begin{aligned}
    \rho_1(e^{i\theta}) &= \rho_1(\cos(\theta) + i\sin(\theta)) \\
                        &= \mattwo{\cos(\theta)}{\sin(\theta)}
                                  {-\sin(\theta)}{\cos(\theta)} = B
  \end{aligned}
  \]


\end{solution}

%\textcolor{red}{TODO}: prove the statement in the solution
% Exercise 1.7
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Describe all elements $A \in \GL{n}{\R}$ with the property $AB=BA$ for all $B \in \GL{n}{\R}$.
\end{taggedexercise}

\begin{solution}
  Matrices $A$ that commute with all matrices in $\GL{n}{\R}$ are scalar multiples of the identity
  \[
  A = \lambda I
  \]
  where $\lambda \in \R$ and $\lambda \neq 0$.
\end{solution}

% Exercise 1.8
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Let $\SL{2}{\Z}$ denote 2 by 2 matrices with integer entries and determinant $1$.
  Prove that $\SL{2}{\Z}$ is a subgroup of $\GL{n}{\Z}$. 
  Is $SL_n(\Z)$ a subgroup of $\GL{n}{\R}$ in general?
\end{taggedexercise}

\begin{solution}
  Fixing $A, B \in \SL{2}{\Z}$, its clear that $A \cdot B$ must have all integer entries.
  Since
  \[
  \det(AB) = \det(A) \det(B) = 1 \cdot 1 = 1
  \]
  we have that $A \cdot B \in \SL{2}{\Z}$ (closure). 
  Next, fix
  \[
    A = \mattwo{a}{b}{c}{d} \in \SL{2}{\Z}
  \]
  Using Cramer's Rule to compute the inverse of $A$ we get 
  \[
  A^{-1} = \frac{1}{ad-bc}\mattwo{d}{-b}{-c}{a} = \mattwo{d}{-b}{-c}{a} 
  \]
  where $ad-bc = 1$ since $\det A = 1$, so $A^{-1}$ has all integer entries, and is a member of $\SL{2}{\Z}$.
  Therefore, $\SL{2}{\Z}$ is a subgroup of $\GL{2}{\R}$.
\end{solution}

The critical step in the above proof is discerning that the factor extracted from $A^{-1}$ is $1/\det A = 1$, which ensures the entries of the inverse are all in $\Z$.
This factor is the same for any $n$, so $\SL{n}{\Z}$ is always a subgroup of $\GL{n}{\R}$ for all $n$.


% Exercise 1.9
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Describe the block matrix blah blabh blabhj \textcolor{red}{TODO} write this out
\end{taggedexercise}
\begin{solution}
  Suppose $A$ and $B$ are block matrices in $M_n(\K)$, given by
  \[
A = \begin{pmatrix}
A_1 & 0   & \cdots & 0 \\
0   & A_2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0   & 0   & \cdots & A_n
\end{pmatrix},
B = \begin{pmatrix}
  B_1 & 0   & \cdots & 0 \\
  0   & B_2 & \cdots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0   & 0   & \cdots & B_n
  \end{pmatrix}
\]
where $\sum \text{dim}A_i = \text{dim}A = \sum \text{dim}B_i = \text{dim}B$, and $\text{dim} A_i = \text{dim}B_i$ for each i.
Then,
\[
  A \cdot B = \begin{pmatrix}
    A_1\cdot B_1 & 0   & \cdots & 0 \\
    0   & A_2 \cdot B_2 & \cdots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0   & 0   & \cdots & A_n \cdot B_n
    \end{pmatrix}
\]
Which can be applied to the above question to derive a simple answer.

\end{solution}

% Exercise 1.10
\begin{taggedexercise}[\textcolor{green}{Complete}]
  If $G_1 \subset \GL{n_1}{\K}$ and $G_2 \subset \GL{n_2}{\K}$ are subgroups, describe a subgroup of $\GL{n_1 + n_2}{\K}$ isomorphic to $G_1 \times G_2$.
\end{taggedexercise}
\begin{solution}
  Define a map 
  \[
  \varphi : G_1 \times G_2 \to \GL{n_1 + n_2}{\K} \\
  \]
  given by
  \[
  (A_1, A_2) \mapsto \mattwo{A_1}{0}
                            {0}  {A_2}
  \]
  The image of $\varphi$ is a subset of $\GL{n_1 + n_2}{\K}$ since

  \[
  \det \mattwo{A_1}{0}
  {0}  {A_2} = \det A_1 \cdot \det A_2 \neq 0
  \]
  so $\varphi(A_1, A_2) \in \GL{n_1 + n_2}{\K}$.
  To prove $\varphi$ is a group homomorphism, observe
  \[
  \begin{aligned}
    \varphi((A_1, A_2) \cdot (B_1, B_2)) &= \varphi(A_1 \cdot B_1, A_2 \cdot B_2) \\
                                         &= \mattwo{A_1 \cdot B_1}{0}{0}{A_2 \cdot B_2} \\
                                         &= \mattwo{A_1}{0}{0}{A_2} \cdot \mattwo{B_1}{0}{0}{B_2} \\
                                         &= \varphi(A_1, A_2) \cdot \varphi(B_1, B_2)
  \end{aligned}
  \]    
  hence the result.

\end{solution}

% \textcolor{red}{TODO}
% Exercise 1.11
\begin{taggedexercise}[\textcolor{red}{TODO}]
  
\end{taggedexercise}

% Exercise 1.12
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Show that for purely imaginary $q_1, q_2 \in \HH$, $-\Re (q_1 \cdot q_2)$ is the vector dot product in $\R^3 = \text{span}(\mathbf{i},
  \mathbf{j},\mathbf{k})$ and $\Im(q_1 \cdot q_2)$ is the vector cross-product.
\end{taggedexercise}

\begin{solution}
  First,
  \[
  \begin{aligned}
    -\Re (q_1 \cdot q_2) &= -\Re ((b_1\mathbf{i} + c_1\mathbf{j} + d_1\mathbf{k}) \cdot (b_2\mathbf{i} + c_2\mathbf{j} + d_2\mathbf{k})) \\
                         &= -\Re((- b_1b_2 - c_1c_2 - d_1d_2) + \dots) \\
                         &= b_1b_2 + c_1c_2 + d_1d_2
  \end{aligned}
  \]
  Next, 
  \[
  \begin{aligned}
    \Im (q_1 \cdot q_2) &= \Im ((b_1\mathbf{i} + c_1\mathbf{j} + d_1\mathbf{k}) \cdot (b_2\mathbf{i} + c_2\mathbf{j} + d_2\mathbf{k})) \\
                        &= (c_1d_2 - d_1c_2)\mathbf{i} + (d_1b_2 - b_1d_2)\mathbf{j} + (b_1c_2 - c_1b_2)\mathbf{j}
  \end{aligned}
  \]
  Mapping $\text{span}(\mathbf{i},\mathbf{j},\mathbf{k})$ to the standard basis in $\R^3$ gives both desired results.
\end{solution}

% \textcolor{red}{TODO}
% Exercise 1.13
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Prove that non-real elements $q_1, q_2 \in \HH$ commute if and only if their imaginary parts are parallel; that is, $\Im(q_1) = \lambda \cdot \Im(q_2)$ for some $\lambda \in \R$.
\end{taggedexercise}

\begin{solution}
  $(\implies)$ Let $\Im(q_1) = \lambda \cdot \Im(q_2)$ for some $\lambda \in \R$, so that
  \[
    \Im(q_1) = b\mathbf{i} + c\mathbf{j} + d\mathbf{k} = \lambda b\mathbf{i} + \lambda c\mathbf{j} + \lambda d\mathbf{k} = \Im(q_2)
  \]
  then,
  \[
  \begin{aligned}
    q_1 \cdot q_2 &= (a_1 + b\mathbf{i} + c\mathbf{j} + d\mathbf{k})\cdot (a_2 + \lambda b\mathbf{i} + \lambda c\mathbf{j} + \lambda d \mathbf{k}) 
    \\
    &=
    \bigl(a_1 a_2 - \lambda\,(b^2 + c^2 + d^2)\bigr)
    b(a_1 \lambda + a_2)\mathbf{i}
    c(a_1 \lambda + a_2)\mathbf{j}
    d(a_1 \lambda + a_2)\mathbf{k} \\
    &= 
    (a_2 + \lambda\,b\,\mathbf{i} + \lambda\,c\,\mathbf{j} + \lambda\,d\,\mathbf{k}) 
    \cdot (a_1 + b\,\mathbf{i} + c\,\mathbf{j} + d\,\mathbf{k}) \\
    &= q_2 \cdot q_1.
    \end{aligned}
  \]
  $(\impliedby)$ Let $q_1 \cdot q_2 = q_2 \cdot q_1$ where
  \[
    q_1 = (a_1 + b_1\mathbf{i} + c_1\mathbf{j} + d_1\mathbf{k}), q_2 = (a_2 + b_2\mathbf{i} + c_2\mathbf{j} + d_2\mathbf{k}).
  \]
  Then the following equalities must hold:

\end{solution}

% \textcolor{red}{TODO}
% Exercise 1.14
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Charachterize the pairs $q_1, q_2 \in \HH$ which anti-commute, that is $q_1q_2 = -q_2q_1$.
\end{taggedexercise}

% Exercise 1.15
\begin{taggedexercise}[\textcolor{green}{Complete}]
  If $q \in \HH$ satisfies $q\mathbf{i} = \mathbf{i}q$, prove that $q \in \C$.
\end{taggedexercise}
\begin{solution}
  Let $q = a + b\mathbf{i} + c\mathbf{j} + d\mathbf{k}$. Then,
  \[
    q\mathbf{i} = a\mathbf{i} + b\mathbf{i}\mathbf{i} + c\mathbf{j}\mathbf{i} + d\mathbf{k}\mathbf{i} = -b + a\mathbf{i} + d\mathbf{j} - c\mathbf{k}
  \]
  and
  \[
    \mathbf{i}q = \mathbf{i}a + b\mathbf{i}\mathbf{i} + c\mathbf{i}\mathbf{j} + d\mathbf{i}\mathbf{k} = -b + a\mathbf{i} - d\mathbf{j} + c\mathbf{k}.
  \]
  Identifying terms gives
  \[
  d = -d \implies d = 0 
  \]
  \[
  c = -c \implies c = 0
  \]
  hence $q = a+bi \in \C$.

\end{solution}

% Exercise 1.16
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove that complex multiplication in $\C \approxeq \R^2$ does not extend to a multiplication operation on $\R^3$ that makes $\R^3$ into a real division algebra.
\end{taggedexercise}

\begin{solution}
  Assume such an extension exists. 
  Consider the map analagous to the extension of $\R^2$ given by
  \[
  (a,b,c) \mapsto a + b\mathbf{i} + c \mathbf{j}
  \]
  with $\mathbf{i}^2 = \mathbf{j}^2 = -1$. 
  Then there must exist a linear map 
  \[
  T: \R^3 \to \R^3
  \]
  with $T^2 = -I$. 
  Represent $T$ by a $3 \times 3$ real matrix $M$. 
  Then $-1$ is in the spectrum of $M^2$ since $M^2 = -I$, thus $\pm i$ is in the spectrum of $M$.
  Since $\det(M) = \prod \lambda_k$ where $\lambda_k$ is an eigenvalue of $M$, there must exist some real value $\lambda$ such that
  \[
  \det(M) = (i)(-i)(\lambda) = \lambda
  \]
  where $\lambda$ must be in $\R$ since complex eigenvalues come in pairs.
  Thus, we must have
  \[
  \det(M^2) = \det(-I) = -1
  \]
  and
  \[
  \det(M^2) = \det(M)^2 = \lambda^2
  \]
  thus $\lambda^2 = -1$, which contradicts $\lambda$ being real.
  
\end{solution}

% Exercise 1.17
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Describe a subgroup of $\GL{n+1}{\R}$ that is isomorphic to $\R^n$ under vector-addition.
\end{taggedexercise}

\begin{solution}
  Consider the matrices of the form 
  \[
  \begin{pmatrix}
  1      & x_1    & x_2    & \cdots & x_n \\
  0      & 1      & 0      & \cdots & 0   \\
  0      & 0      & 1      & \cdots & 0   \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
  0      & 0      & 0      & \cdots & 1
  \end{pmatrix} \in \GL{n+1}{\R}
  \]
  and the map that takes such matrices to $(x_1, \dots , x_n) \in \R^n$.

\end{solution}

% Exercise 1.18
\begin{taggedexercise}[\textcolor{green}{Complete}]
  If $\lambda \in \HH$ commutes with every element of $\HH$, prove that $\lambda \in \R$.
\end{taggedexercise}

\begin{solution}
  Let $\lambda$ have the property that $\lambda \cdot w = w \cdot \lambda$ for all $w \in \HH$.
  Letting $w = \mathbf{i}$, $\lambda \in \C$ per Exercise 1.15.
  Letting $\lambda = a+b\mathbf{i}$ and $w = \mathbf{j}$, we must have
  \[
    (a+b\mathbf{i}) \cdot \mathbf{j} = a\mathbf{j} + b\mathbf{k} = a\mathbf{j} - b\mathbf{k} = \mathbf{j}(a+b \mathbf{i})
  \]
  hence $b = -b \implies b = 0$, therefore $\lambda = a \in \R$.
  
\end{solution}

%==============================================================================
\chapter{All matrix groups are real matrix groups}
%==============================================================================
\section{Exercises}

% Exercise 2.1
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove that $\rho_n$ makes the diagram in 2.1 commute.
\end{taggedexercise}

\begin{solution}
  First, note the definition of $\rho_n$, that is 
  \[\rho_1(a + b\mathfrak{i}) := \mattwo{a}{b}{-b}{a}\]
  Say $A \in M_n(\C)$, then the map $\rho_n : M_n(\C) \to M_{2n}$ is simply given by
  \[
\rho_n(A) = \rho_n \left(
\begin{bmatrix}
z_{11} & z_{12} & \cdots & z_{1n} \\
z_{21} & z_{22} & \cdots & z_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
z_{n1} & z_{n2} & \cdots & z_{nn}
\end{bmatrix}\right) 
:= \begin{bmatrix}
  \rho_1(z)_{11} & \rho_1(z)_{12} & \cdots & \rho_1(z)_{1n} \\
  \rho_1(z)_{21} & \rho_1(z)_{22} & \cdots & \rho_1(z)_{2n} \\
  \vdots & \vdots & \ddots & \vdots \\
  \rho_1(z)_{n1} & \rho_1(z)_{n2} & \cdots & \rho_1(z)_{nn}
  \end{bmatrix}
\]
where each $\rho_1(z)_{ij}$ is a $2 \times 2$ block matrix as defined above.
We want to show the following diagram commutes:
\[\begin{tikzcd}
	{\C^n} &&& {\R^{2n}} \\
	\\
	{\C^n} &&& {\R^{2n}}
	\arrow["{f_n}", from=1-1, to=1-4]
	\arrow["{R_A}"', from=1-1, to=3-1]
	\arrow["{R_{\rho_{n}(A)}}", from=1-4, to=3-4]
	\arrow["{f_n}", from=3-1, to=3-4]
\end{tikzcd}\]
where
\[f_n(a_1 + b_1\mathbf{i}, \dots, a_n + b_n\mathbf{i}) := (a_1, b_1, \dots, a_n, b_n)\]
and $A \in M_n(\C)$.
Let $z = a+b\mathbf{i} \in \C^1$ and $A = c+d\mathbf{i} \in \C^1$.
Then,
\[f_1 \circ R_A(z) = f_1 ((ac-bd) + (ad+bc)\mathbf{i}) = (ac-bd, ad+bc)\]
and
\[R_{\rho_{1}(A)} \circ f_1(z) = R_{\rho_{1}(A)}(a, b) = (ac-bd, ad+bc).\]
Inducting over $n$ using the definition of matrix multiplication and block matrix multiplication produces the result.

\end{solution}

% Exercise 2.2
\begin{taggedexercise}[\textcolor{red}{TODO}]
  
\end{taggedexercise}

% Exercise 2.3
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Prove proposition 2.6.
\end{taggedexercise}

% Exercise 2.4
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Prove proposition 2.7.
\end{taggedexercise}

% Exercise 2.5
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove that for any $A \in M_1(\HH)$, $\det(A) \in \R$.
\end{taggedexercise}

\begin{solution}
  Let $A = z+w\mathbf{j} \in M_n(\HH)$.
  Then,
  \[\begin{aligned}
    \det(A) &= \det \circ \Psi_1(A)\\
           &= \det \mattwo{z}{w}{-\bar{w}}{\bar{z}} \\
           &= z \cdot \bar{z} + w \cdot \bar{w} \\
           &= \Re(z)^2 + \Im(z)^2 + \Re(w)^2 + \Im(z)^2 \in \R
  \end{aligned}\]
\end{solution}

% Exercise 2.6
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove that $\SL{n}{\HH} = \{A \in \GL{n}{\HH} : \det(A) = 1\}$ is a subgroup.
  Describe a natural bijection between elements of $\SL{1}{\HH}$ and elements of the 3-sphere $S^3$.
\end{taggedexercise}

\begin{solution}
  Fix $A, B \in \SL{n}{\HH}$.
  Then,
  \[
  \begin{aligned}
    \det(AB) &= \det \circ \Psi_n(AB) \\
             &= \det \left(\Psi_n(A) \cdot \Psi_n(B) \right) \\
             &= \det(\Psi_n(A)) \cdot \det(\Psi_n(B)) \\
             &= (1) \cdot (1) = 1
  \end{aligned}
  \]    
  hence, $\SL{n}{\HH}$ is closed. 
  Next, 
  \[\begin{aligned}
    1 &= \det(I) \\
      &= \det(AA^{-1}) \\
      &= \det \circ \Psi_n(AA^{-1}) \\
      &= \det \left(\Psi_n(A) \cdot \Psi_n(A^{-1}) \right) \\
      &= \det(\Psi_n(A)) \cdot \det(\Psi_n(A^{-1})) \\
      &= (1) \cdot \det(\Psi_n(A^{-1})) \\
      &\implies \det(A^{-1}) = 1 \implies A^{-1} \in \SL{n}{\HH}
  \end{aligned}\]
  hence $\SL{n}{\HH}$ is a subgroup.
  From Exercise 2.6, we have that for any $A = a +b\mathbf{i} + c\mathbf{j} + d\mathbf{k} \in \SL{n}{\HH}$ we have that 
  \[1 = \det(A) = a^2 + b^2 + c^2 + d^2\]
  hence, the map 
  \[a + b\mathbf{i} + c\mathbf{j} + d\mathbf{k} \mapsto (a, b, c, d) \in S^3\]
  is obviously a bijection.
\end{solution}

% Exercise 2.7
\begin{taggedexercise}[\textcolor{red}{TODO}]
  
\end{taggedexercise}

% Exercise 2.8
\begin{taggedexercise}[\textcolor{red}{TODO}]
  
\end{taggedexercise}

% Exercise 2.9
\begin{taggedexercise}[\textcolor{red}{TODO}]
  
\end{taggedexercise}

% Exercise 2.10
\begin{taggedexercise}[\textcolor{red}{TODO}]
  
\end{taggedexercise}

% Exercise 2.11
\begin{taggedexercise}[\textcolor{red}{TODO}]
  
\end{taggedexercise}

% Exercise 2.12
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Let $q \in \HH$ and define $\C \cdot q := \{\lambda \cdot q : \lambda \in \C\}$ and $q \cdot \C := \{q \cdot \lambda : \lambda \in \C\}$.
  \begin{enumerate}
    \item With $g_1: \HH \to \C^2$ defined as in section Section 2, show that $g_1(\C \cdot q)$ is a one-dimensional $\C-$subspace of $\C^2$.
    \item Define a natural identification $\hat{g}_1 : \HH \to \C^2$ so that $\hat{g}_1(q\cdot\C)$ is a one-dimensional $\C-$subspace of $\C^2$.
  \end{enumerate}
\end{taggedexercise}

\begin{solution}
  (1). Let $q = z+w\mathbf{j} \in \HH$ and $z,w \in \C$.
  Then,
  \[\begin{aligned}
    g_1(\C \cdot q) &= \{g_1(\lambda \cdot q) : \lambda \in \C\} \\
                    &= \{g_1(\lambda z + \lambda w \mathbf{j}): \lambda, z, w \in \C\} \\
                    &= \{(\lambda z, \lambda w ): \lambda, z, w \in \C\} \\
                    &= \{\lambda \cdot (z, w): \lambda, z, w \in \C\}
  \end{aligned}\]
  where $z$ and $w$ are determined by $q$ (hence they are fixed), and so $g_1(\C \cdot q)$ is clearly a one-dimensional $\C-$subspace of $\C^2$.

  (2). Let $\iota: \HH \to \HH$ be given by $\iota(q) = \iota(z + w\mathbf{j}) = \iota(z + \mathbf{j}w)$ with $z,w \in \C$ and $f_1 : \HH \to \C^2$ given by
  \[f_1(w+\mathbf{j}z):= (w, z).\]
  Then, let $\hat{g}_1 = f_1 \circ \iota$.
  Therefore,
  \[\begin{aligned}
    \hat{g}_1(q \cdot \C) &= \{\hat{g}_1(q \cdot \lambda) : \lambda \in \C\} \\
                          &= \{f_1 \circ \iota(q \cdot \lambda) : \lambda \in \C\} \\
                          &= \{f_1(z\lambda + \mathbf{j}w\lambda): \lambda, z, w \in \C\} \\
                          &= \{(z\lambda, w\lambda): \lambda, z, w \in \C\} \\
                          &= \{\lambda \cdot (z, w): \lambda, z, w \in \C\} 
  \end{aligned}\]
  which is the same subspace from part (1), hence the result.
\end{solution}

%==============================================================================
\chapter{The orthogonal groups}
%==============================================================================
\section{Exercises}

% Exercise 3.1
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove part (4) of Proposition 3.3:
  \[
  \overline{\langle X, Y \rangle} = \langle Y, X \rangle
  \]
\end{taggedexercise}
\begin{solution}
  \[
  \begin{aligned}
    \overline{\langle X, Y \rangle} &= \overline{\langle (x_1, \dots , x_n), (y_1, \dots , y_n) \rangle} \\
                                    &= \overline{x_1\bar{y_1} + \dots + x_n\bar{y_n}} \\
                                    &= \overline{x_1 \bar{y_1}} + \dots + \overline{x_n \bar{y_n}} \\
                                    &= y_1\bar{x_1} + \dots + y_n\bar{x_n} \\
                                    &= \langle (y_1, \dots , y_n), (x_1, \dots , x_n) \rangle \\
                                    &= \langle Y, X \rangle
  \end{aligned}
  \]
\end{solution}


% Exercise 3.2
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove Equations 3.5 and 3.6:
  \[
    (3.5) :  \langle X, Y \rangle_\C = \langle f(X), f(Y) \rangle_\R + \mathbf{i} \langle f(X), f(\mathbf{i}Y) \rangle_\R
  \]
  \[
    (3.6) : |X|_\C = |f(X)|_R
  \]
  where
  \[
  f = f_n: \C^{n} \to \R^{2n}
  \]
  is given by
  \[
  f(a_1 + b_1\mathbf{i}, \dots , a_n+b_n\mathbf{i}) := (a_1, b_1, \dots, a_n, b_n).
  \]
\end{taggedexercise}

\begin{solution} First, for Equation 3.5,
  \[
  \begin{aligned}
      \langle X, Y \rangle_\C &= \langle (a_1 + b_1\mathbf{i}, \dots , a_n + b_n\mathbf{i}), (c_1+d_1\mathbf{i}, \dots , c_n+d_n\mathbf{i}) \rangle_\C \\
                              &= (a_1 + b_1\mathbf{i})\overline{(c_1+d_1\mathbf{i})} + \dots + (a_n + b_n\mathbf{i})\overline{(c_n+d_n\mathbf{i})} \\
                              &= (a_1 + b_1\mathbf{i})(c_1-d_1\mathbf{i}) + \dots + (a_n + b_n\mathbf{i})(c_n-d_n\mathbf{i}) \\
                              &= [(a_1c_1 + b_1d_1) + (-a_1d_1 + b_1c_1)\mathbf{i}] + \dots + [(a_nc_n + b_nd_n) + (-a_nd_n + b_nc_n)\mathbf{i}] \\
                              &= (a_1c_1 + b_1d_1 + \dots + a_nc_n + b_nd_n) + (-a_1d_1 + b_1c_1 + \dots - a_nd_n + b_nc_n)\mathbf{i} \\
                              &= \langle (a_1, b_1, \dots , a_n, b_n), (c_1, d_1, \dots c_n, d_n) \rangle_\R + \mathbf{i}\langle (a_1, b_1, \dots , a_n, b_n), (-d_1, c_1, \dots , -d_n, c_n) \rangle_\R \\
                              &= \langle f(X), f(Y) \rangle_\R + \mathbf{i}\langle f(X), \underbrace{f(\mathbf{i}Y)}_! \rangle_\R
    \end{aligned}
  \]
  where the equality of $\underbrace{f(\mathbf{i}Y)}_!$ is due to
  \[
  \begin{aligned}
    f(\mathbf{i}Y) &= f(\mathbf{i}(c_1 + d_1\mathbf{i}, \dots , c_n + d_n\mathbf{i})) \\
                   &= f((-d_1 + \mathbf{i}c_1, \dots, -d_n + \mathbf{i}c_n)) \\
                   &= (-d_1, c_1, \dots, -d_n, c_n)
  \end{aligned}
  \]
  Next, for Equation 3.6,
  \[
  \begin{aligned}
    |X|_\C &= \sqrt{\langle X, X \rangle_\C} \\
           &= \sqrt{\langle (a_1 + b_1\mathbf{i}, \dots , a_n + b_n\mathbf{i}), (a_1 + b_1\mathbf{i}, \dots , a_n + b_n\mathbf{i}) \rangle_\C} \\
           &= \sqrt{(a_1 + b_1\mathbf{i})(a_1 - b_1\mathbf{i}) + \dots + (a_n + b_n\mathbf{i})(a_n - b_n\mathbf{i})} \\
           &= \sqrt{a_1^2 + b_1^2 + \dots + a_n^2 + b_n^2} \\
           &= \sqrt{\langle (a_1, b_1, \dots, a_n, b_n), (a_1, b_1, \dots, a_n, b_n) \rangle}\\
           &= \sqrt{\langle f(X), f(X) \rangle}_\R \\
           &= |f(X)|_\R
  \end{aligned}
  \]
\end{solution}

% \textcolor{red}{TODO}
% Exercise 3.3
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Prove Proposition 3.5, that is $\{X_1, \dots X_n\} \in \C^n$ is an orthonormal basis if and only if $\{f(X_1), f(\mathbf{i}X_1), \dots ,f(X_n), f(\mathbf{i}X_n)\}$ is an othonormal basis of $\R^{2n}$. 
\end{taggedexercise}

\begin{solution}
  ($\implies$) Let $\{Y_1, \dots Y_{2n}\} = \{f(X_1), f(\mathbf{i}X_1), \dots ,f(X_n), f(\mathbf{i}X_n)\}$ be an orthonorml basis of $\R^{2n}$.
  Then,
  \[
  \langle Y_i, Y_j \rangle_\R = \delta_{ij}
  \]
  where $\delta_{ij}$ is the Kronecker Delta.
  Next, consider
  \[
  \begin{aligned}
    \langle f^{-1}(Y_i), f^{-1}(Y_j) \rangle_\R &= f^{-1}()
  \end{aligned}
  \]
  ($\impliedby$) Let $X, Y \in \C^n$ be orthogonal.
  Then,
  \[
  \langle X, Y \rangle_\C = \langle f(X), f(Y) \rangle_\R + \mathbf{i} \langle f(X), f(\mathbf{i}Y) \rangle_\R = 0
  \]
  Since $\langle f(X), f(\mathbf{i}Y) \rangle_\R \in \R$, and hence $\mathbf{i}\langle f(X), f(\mathbf{i}Y) \rangle_\R \in \C$, both factors must vanish.
  Hence, $f$ maps $\C^n$ to an orthonormal basis of $\R^{2n}$.

\end{solution}


% Exercise 3.4
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove Proposition 3.18, that is, for any $X \subset \R^n$, $\text{Symm}^+(X) \subset \text{Symm}(X)$ is a subgroup with index $1$ or $2$.
\end{taggedexercise}

\begin{solution}
  First, to show $\text{Symm}^+(X)$ is a subgroup, let $A, B \in \text{Symm}^+(X)$. 
  Then,
  \[
  \det(AB) = \det(A)\det(B) = 1 \cdot 1 = 1 \implies AB \in \text{Symm}^+(X)
  \]
  and
  \[
  1 = \det(I) = \det(AA^{-1}) = \det(A)\det(A^{-1}) = \det(A^{-1}) \implies A{-1} \in \text{Symm}^+(X)
  \]
  so $\text{Symm}^+(X)$ is a subgroup. 
  It's clear that $\text{Symm}^+(X)$ has at most $2$ cosets given the symmetry of the determinant, and has $1$ if $\text{Symm}^+(X) = \text{Symm}(X)$, hence it's index is $1$ or $2$.
\end{solution}

% Exercise 3.5
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Let $A \in \GL{n}{\K}$. Prove that $A \in \text{O}_n(\K)$ if and only if the columns of $A$ are an orthonormal basis of $\K^n$.
\end{taggedexercise}

\begin{solution}
  ($\implies$) Let the columns of $A$ form an orthonormal basis $\{ v_1, \dots, v_n \}$ of $\K^n$.
  Thus,
  \[
  \begin{aligned}
    \langle v_i, v_j \rangle &= \delta_{ij}
  \end{aligned}
  \]
  where $\delta_{ij}$ is the Kronecker Delta.
  Next,
  \[
    (A^*A)_{ij} = \sum_{k = 1}^n A^*_{ij}A_{kj} = \sum_{k = 1}^n A_{ki}A_{kj}
  \]
  where $A_{ki}$ is the $k$th component of $v_i$, hence
  \[
    (A^*A)_{ij} = \langle v_i, v_j \rangle = \delta_{ij} \implies A^*A = I
  \] 

  ($\impliedby$) Fix some $A \in \text{O}_n(\K)$ with columns $\{ v_1, \dots, v_n \}$.
  Since $A$ is an element of a group, $A^{-1}$ is defined, and so the columns are linearly independent.
  Next, 
  \[
  \begin{aligned}
    (I)_{ij} &= (A^*A)_{ij} \\
             &= \langle v_i, v_j \rangle \\
             &= \delta_{ij}
  \end{aligned}
  \]     
  Hence, the columns are orthonormal.


\end{solution}

% Exercise 3.6
\begin{taggedexercise}[\textcolor{green}{Complete}]
  \begin{enumerate}
    \item Show that for every $A \in \Ogroup{2} - \SO{2}$, $R_A: \R^2 \to \R^2$ is a flip about some line through the origin. How is this line determined by the angle of $A$?
    \item Let $B = \mattwo{\cos \theta}{\sin \theta}{-\sin\theta}{\cos\theta} \in \SO{2}$. Assume $\theta$ is not an integer multiple of $\pi$. Prove that $B$ does not commute with any $A \in \Ogroup{2} - \SO{2}$.
  \end{enumerate}
\end{taggedexercise}

\begin{solution}
  (1). First, note that given some $X = (x_1, x_2) \in \R^2$,
  \[
    (x_1, x_2)\mattwo{1}{0}{0}{-1} = (x_1, -x_2)
  \]
  hence, $\mattwo{1}{0}{0}{-1}$ corresponds to a flip through the $x$-axis.
  Per Equation 3.8, we have
  \[
  A = \mattwo{\cos\theta}{\sin\theta}{\sin\theta}{-\cos\theta}
  \]
  where $\theta \in [0, 2\pi)$.
  Using this, observe that
  \[
    A = \mattwo{\cos\theta}{\sin\theta}{\sin\theta}{-\cos\theta} = \mattwo{1}{0}{0}{-1} \mattwo{\cos \theta}{\sin \theta}{-\sin\theta}{\cos\theta}
  \]
  where the second factor on the RHS is in $\SO{2}$ and corresponds to a counter-clockwise rotation of $\theta$.
  Hence, $A$ is a rotation flip then rotation.

  (2) Let $B \in \SO{2}$. Then 
  \[
  R_{AB}((x_1, x_2)) = XAB = (x_{1, \theta}, -x_{2, \theta})B = (x_{1, \theta + \varphi}, -x_{2, \theta + \varphi})
  \]
  is given by the flip of the first factor of $A$, then the rotations $\theta$ and $\varphi$ of the next two factors.
  However,
  \[
  R_{BA}((x_1, x_2)) = XBA = (x_{1, \varphi}, x_{2, \varphi})A.
  \]
  In this case, $x_{2, \varphi}$ will first be flipped and then rotated by $\theta$, and so we cannot assert that it is equal to $-x_{2, \varphi + \theta}$, hence the matrices cannot commute.

\end{solution}

% \textcolor{red}{TODO}
% Exercise 3.7
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Describe the product of any two elements in $O(2)$ in terms of their angles.
\end{taggedexercise}

\begin{solution}
  Let $A, B \in \SO{2}$ and $C, D \in O(2) - \SO{2}$.
  We need to describe $R_{AB}$, $R_{CD}$, and $R_{AC}$.
  First, 
  \[
  \begin{aligned}
    R_{AB} &= \mattwo{\cos \theta}{\sin \theta}{-\sin\theta}{\cos\theta} \mattwo{\cos \varphi}{\sin \varphi}{-\sin\varphi}{\cos\varphi} \\
           &= \mattwo{\cos\theta\cos\varphi - \sin\theta\sin\varphi}{-\sin\theta\cos\varphi - \sin\varphi\cos\theta}{\cos\theta\sin\varphi + \cos\varphi\sin\theta}{-\sin\theta\sin\varphi + cos\theta\cos\varphi} \\
           &= \mattwo{\cos(\theta + \varphi)}{\sin(\theta + \varphi)}{-\sin(\theta + \varphi)}{\cos(\theta + \varphi)}
  \end{aligned}
  \]
\end{solution}

%\textcolor{red}{TODO}
% Exercise 3.8
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

%\textcolor{red}{TODO}
% Exercise 3.9
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}


% Exercise 3.10
\begin{taggedexercise}[\textcolor{green}{Complete}]
Prove that $\text{Trans}(\R^n)$ is a normal subgroup of $\text{Isom}(\R^n)$.
\end{taggedexercise}

\begin{solution}
  Fix $\mattwo{A}{0}{X}{1} \in \text{Isom}(\R^n)$.
  Then,
  \[\begin{aligned}
    A \cdot \text{Trans}(\R^n) &= \mattwo{A}{0}{X}{1} \cdot \left\{\mattwo{I}{0}{Y}{1} : Y \in \R^n \right\} \\
                               &= \left\{\mattwo{A}{0}{X + Y}{1} : Y \in \R^n \right\}
  \end{aligned}\]
  and
  \[\begin{aligned}
    \text{Trans}(\R^n) \cdot A &= \left\{\mattwo{I}{0}{Y}{1} : Y \in \R^n \right\} \cdot \mattwo{A}{0}{X}{1} \\
                               &= \left\{\mattwo{A}{0}{X + R_A(Y)}{1} : Y \in \R^n \right\}
  \end{aligned}\]
  $R_A$ is one-to-one and onto, so we can always identify $X + Y_1$ with some $X + R_A(Y_2)$ with $Y_1, Y_2$ unique, hence both cosets are equivalent, and $\text{Trans}(\R^n)$ is normal.
\end{solution}

% Exercise 3.11
\begin{taggedexercise}[\textcolor{green}{Complete}]
Prove that the Affine group
\[
\text{Aff}_n(\K) = \left\{\mattwo{A}{0}{V}{1} : A \in \GL{n}{\K}, V \in \K^n \right\}
\]
\begin{enumerate}
  \item Is a subgroup of $\GL{n+1}{\K}$
  \item Prove that $f(X) := R_A(X) + V$ sends translated lines to translated lines
\end{enumerate}
\end{taggedexercise}

\begin{solution}
  (1). First, note that
  \[
  \mattwo{A_1}{0}{V_1}{1} \cdot \mattwo{A_2}{0}{V_2}{1} = \mattwo{A_1 \cdot A_2}{0}{R_{A_2}(V_1) + V_2}{1} 
  \]
  so $\text{Aff}_n(\K)$ is closed.
  Next, 
  \[\mattwo{A}{0}{V}{1} \cdot \mattwo{A^{-1}}{0}{ - R_{A^{-1}}(V)}{1} = \mattwo{AA^{-1}}{0}{R_{A^{-1}}(V) - R_{A^{-1}}(V)}{1} = \mattwo{I}{0}{0}{1}\]
  hence $\text{Aff}_n(\K)$ is a subgroup.

  (2). This is trivial since $\text{Aff}_n(\K)$ is a subgroup.
\end{solution}

% Exercise 3.12
\begin{taggedexercise}[\textcolor{green}{Complete}]
Is $\text{Aff}_1(\R)$ abelian?
\end{taggedexercise}

\begin{solution}
Think of $\text{Aff}_1(\R)$ as maps $f_{\lambda, V}(X) = \lambda X + V$.
Then
\[\begin{aligned}
  f_{\lambda_2, V_2} \circ f_{\lambda_1, V_1}(X) &= f_{\lambda_2, V_2}(\lambda_1 X + V_1) \\
                                                 &= \lambda_2 \lambda_1 X + \lambda_2 V_1 + V_2
\end{aligned}\]
\[\begin{aligned}
  f_{\lambda_1, V_1} \circ f_{\lambda_2, V_2}(X) &= f_{\lambda_1, V_1}(\lambda_2 X + V_2) \\
                                                 &= \lambda_1 \lambda_2 X + \lambda_1 V_2 + V_1
\end{aligned}\]
which are equal if and only if $\lambda_1 = \lambda_2 = 1$, hence elements in $\text{Aff}_1(\R)$ do not commute in general, so $\text{Aff}_1(\R)$ is not abelian.
\end{solution}

% Exercise 3.13
\begin{taggedexercise}[\textcolor{green}{Complete}]
Let 
\[
A = \begin{bmatrix}
  0 & 0 & 0 & 1 \\
  1 & 0 & 0 & 0 \\
  0 & 1 & 0 & 0 \\
  0 & 0 & 1 & 0
  \end{bmatrix}
\]
\begin{enumerate}
  \item Calculate $R_A(x,y,z,w)$.
  \item Define a subgroup $H$ of $O(4)$ that is isomorphic to $S_4$.
  \item Describe a subgroup $H$ of $O(n)$ that is isomorphic to $S_n$. What is $H \cap SO(n)$?
  \item Prove that every finite group is a subgroup of $O(n)$ for some $n$.
\end{enumerate}
\end{taggedexercise}

\begin{solution}
  (1). 
  \[
  R_A(x,y,z,w) = (x,y,z,w) \cdot \begin{bmatrix}
    0 & 0 & 0 & 1 \\
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0
    \end{bmatrix} = (y, z, w, x).
  \]

  (2). Let $\{e_1, e_2, e_3, e_4\}$ be the standard basis of $\R^4$ and $\sigma \in S_4$ a permutation on $4$ charachters.
  Then define a map $f : S_n \to O(4)$ via

  \[f(\sigma) := 
  \begin{bmatrix}
  | & | & | & | \\
  e_{\sigma(1)} & e_{\sigma(2)} & e_{\sigma(3)} & e_{\sigma(4)} \\
  | & | & | & |
  \end{bmatrix}.
  \]
  Then,
  \[
  \begin{aligned}
    f(\sigma_1 \circ \sigma_2) &= 
  \begin{bmatrix}
  | & | & | & | \\
  e_{\sigma_1 \circ \sigma_2(1)} & e_{\sigma_1 \circ \sigma_2(2)} & e_{\sigma_1 \circ \sigma_2(3)} & e_{\sigma_1 \circ \sigma_2(4)} \\
  | & | & | & |
  \end{bmatrix} \\
  &= \begin{bmatrix}
    | & | & | & | \\
    e_{\sigma_1(1)} & e_{\sigma_1(2)} & e_{\sigma_1(3)} & e_{\sigma_1(4)} \\
    | & | & | & |
    \end{bmatrix} \cdot
    \begin{bmatrix}
      | & | & | & | \\
      e_{\sigma_2(1)} & e_{\sigma_2(2)} & e_{\sigma_2(3)} & e_{\sigma_2(4)} \\
      | & | & | & |
      \end{bmatrix} \\
  &= f(\sigma_1) \circ f(\sigma_2)
  \end{aligned}
  \]
  Hence $f$ is a group homomorphism.
  Note that $\ker{f}$ is trivial, so $H = \text{Image} f \approxeq S_4$ is a subgroup of $O(4)$.

  (3). Let $\{e_1, \dots, e_n\}$ be the standard basis of $\R^n$ and $\sigma \in S_n$ a permutation on $n$ charachters.
  Then define a map $f : S_n \to O(n)$ via

  \[f(\sigma) := 
  \begin{bmatrix}
  | & | &  & | & |\\
  e_{\sigma(1)} & e_{\sigma(2)} & \cdots & e_{\sigma(3)} & e_{\sigma(4)} \\
  | & | &  & | & |
  \end{bmatrix}.
  \]
  Let $H = \text{image} f \approxeq S_n$, which is a subgroup of $O(n)$ generalizing the logic from step (2).
  Consider the diagram
  \[\begin{tikzcd}
	{S_n} &&& {O(n)} \\
	\\
	&&& {\{\pm 1\}}
	\arrow["f", from=1-1, to=1-4]
	\arrow["{\text{sgn}}"', from=1-1, to=3-4]
	\arrow["\det", from=1-4, to=3-4]
\end{tikzcd}\]
  $f, \text{sgn}$, and $\det$ are all group homomorphisms (where the operation in $\{\pm 1\}$ is multiplication), hence the diagram must commute.
  Therefore $H \cap SO(n)$ is the permutation matrices in $H$ corresponding to permutations with positive sign in the pre-image of $f$.

  (4). By Cayley's Theorem for finite groups $G$, $G \leq H \leq O(n)$, and since subgroups of subgroups are subgroups, $G \leq O(n)$. 

\end{solution}


% Exercise 3.14
\begin{taggedexercise}[\textcolor{green}{Complete}]
Let $\mathfrak{g}$ be a $\K-$subspace of $\K^n$, with dimension $d$.
Let $\beta = \{X_1, \dots, X_d\}$ be an orthonormal basis of $\mathfrak{g}$.
Let $f: \mathfrak{g} \to \mathfrak{g}$ be $\K-$linear.
Let $A \in M_d(\K)$ represent $f$ over the basis $\beta$.
Prove that the following are equivalent:
\begin{enumerate}
  \item $A \in O_d(\K)$
  \item $\langle f(X), f(Y) \rangle = \langle X, Y \rangle$ for all $X, Y \in \mathfrak{g}$.
\end{enumerate}
Show by example that this is false when $\beta$ is not orthogonormal.
\end{taggedexercise}

\begin{solution}
  ((1) $\implies$ (2)). Let $A \in O_d(\K)$.
  Then for any $X, Y \in \mathfrak{g}$, 
  \[
  \begin{aligned}
    \langle f(X), f(Y) \rangle &= \langle R_A(X), R_A(Y) \rangle \\
                               &= \langle X \cdot A, Y \cdot A \rangle \\
                               &= \langle X, Y \rangle
  \end{aligned}
  \]
  by the definition of $O_d(\K)$.

  ((2) $\implies$ (1)). Let $\langle f(X), f(Y) \rangle = \langle X, Y \rangle$ for all $X, Y \in \mathfrak{g}$.
  Then for any $X_i, X_j \in \beta$,
  \[\begin{aligned}
    \langle f(X_i), f(X_j) \rangle &= \langle X_i, X_j \rangle \\
                                   &= \delta_{ij}
  \end{aligned}\]
  Thus, representing $f$ as $A$ must be done in a way so that $A$ is invariant under the inner product.
  In other words, $A \in O_d(\K)$.
  Hence, (1) $\iff$ (2).

  Say that $\beta = \{1,2\mathbf{i}\}$ is a basis of $\C$.
  Then let $f(z) = ze^{\mathbf{i}\pi/2}$, hence $A \in U(1) \approxeq O_2(\R)$.
  Then,
  \[
  \begin{aligned}
    \langle f(1), f(2\mathbf{i}) \rangle &=  \langle e^{\mathbf{i} \pi/2}, 2\mathbf{i}e^{\mathbf{i}\pi/2} \rangle \\
                                         &= \langle \mathbf{i}, -2 \rangle \\
                                         &= -2\mathbf{i} \\
                                         &\neq 2\mathbf{i} \\
                                         &= \langle 1, 2\mathbf{i} \rangle
  \end{aligned}
  \]



\end{solution}

% Exercise 3.15
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove that the symmetries of the tetrahedron form the group $S_4$ and the proper symmetries form the group $A_4$.
\end{taggedexercise}

\begin{solution}
  Fix a vertex $v \in \{v_1, v_2, v_3, v_4\}$ of the tetrahedron.
  Consider the symmetries of the face opposite to $v$, which consist of $3$ rotational symmetries and $3$ flips. 
  Hence there are $4 \cdot (3 + 3) = 4!$ elements.
  Since clearly the symmetries act on the set $\{v_1, v_2, v_3, v_4\}$, and there are $4!$ distinct actions, the symmetries of the tetrahedron must be isomorphic to $S_4$.

  Exactly $1/2$ of the elements are the rotational symmetries described above, which are orientation preserving.
  There are $4!/2$ of these, corresponding directly the subgroup $A_4$.

\end{solution}

% Exercise 3.16
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Think of $\Sp{1}$ as the group of unit length quarternions, that is $\Sp{1} = \{ q \in \HH : |q| = 1 \}$.
  \begin{enumerate}
    \item Show that the conjugation map $C_q : \HH \to \HH$ given by $C_q(v) := q v \bar{q}$ is an orthogonal linear transformation. Thus, w.r.t the natural basis $\{1, \mathbf{i}, \mathbf{j}, \mathbf{k}\}$, $C_q$ can be regaurded as an element of $\Ogroup{4}$.
    \item For every $q \in \Sp{1}$, show that $C_q(1) = 1$ and therefore that $C_q$ sends $\text{span}\{\mathbf{i}, \mathbf{j}, \mathbf{k}\}$ to itself. Conclude that the restriction $C_q \big|_{\Im(\HH)}$ can be regaurded as an element of $\Ogroup{3}$.
    \item Define $\varphi : \Sp{1} \to \Ogroup{3}$ given by $\varphi(q) := C_q \big|_{\Im(\HH)}$. Verify $\varphi$ is a group homomorphism.
    \item Verify that the kernel of $\varphi$ is $\{1, -1\}$ and therefore $\varphi$ is two-to-one.
  \end{enumerate}
\end{taggedexercise}

\begin{solution}
  (1). To show $C_q$ is linear, let $v, w \in \HH$, then
  \[\begin{aligned}
    C_q(v + w) &= q(v+w)\bar{q} \\
               &= q(v\bar{q} + w\bar{q}) \\
               &= qv\bar{q} + qw\bar{q} \\
               &= c_q(v) + C_q(w).
  \end{aligned}\]
  Next, fix $\lambda \in \R$. Then,
  \[
  \begin{aligned}
    C_q(\lambda v) &= q(\lambda v)\bar{q} \\
                   &= \lambda(qv\bar{q}) \\
                   &= \lambda C_q(v)
  \end{aligned}
  \]    
  hence $C_q$ is a linear transformation.
  To show $C_q$ is orthogonal, note that
  \[
  \begin{aligned}
    \langle C_q(v), C_q(w) \rangle &= \langle qv\bar{q}, qw\bar{q} \rangle \\
                                   &= \Re(\overline{qv\bar{q}} \cdot qw\bar{q}) \\
                                   &= \Re(\overline{v\bar{q}}\bar{q} \cdot qw\bar{q}) \\
                                   &= \Re(\overline{v\bar{q}}(\bar{q}q)w\bar{q}) \\
                                   &= \Re(\overline{v\bar{q}}w\bar{q}) \\
                                   &= \Re(\overline{v\bar{q}}w\bar{q}) \\
                                   &= \Re(q\bar{v}w \bar{q}) \\
                                   &\stackrel{*}{=} \Re(\bar{v}w) \\
                                   &= \langle v, w\rangle 
  \end{aligned}
  \]
  where the $\stackrel{*}{=}$ step can be verified using
  \[\Re(qx \bar{q})= \frac{1}{2} q(x + \bar{x})\bar{q} = \frac{1}{2}\cdot 2\Re(x) \cdot q\bar{q} = \Re(x)\] 
  Therefore, $C_q$ can be regaurded as an element of $\Ogroup{4}$ by identifying it with a matrix $A \in \Ogroup{4}$ so that the following commutes:
  \[\begin{tikzcd}
    {\{1, \mathbf{i}, \mathbf{j}, \mathbf{k}\}} &&& \HH \\
    \\
    \\
    {\{e_1, e_2, e_3, e_4\}} &&& {\R^4}
    \arrow["{C_q}", from=1-1, to=1-4]
    \arrow["\pi"', from=1-1, to=4-1]
    \arrow["{A}"', from=4-1, to=4-4]
    \arrow["\rho", from=1-4, to=4-4]
  \end{tikzcd}\]
  where $\pi$ and $\rho$ are the obvious maps.

  (2). Note that
  \[
    C_q(1) = q(1)\bar{q} = q\bar{q} = 1
  \]  
  since $C_q$ is linear,
  \[
    C_q(v) = C_q(\Re(v) + \Im(v)) = C_q(\Re(v)) + C_q(\Im(v)) = \Re(v) + C_q(\Im(v))
  \]
  fixing $\Re(v) = 0$, it follows that $C_q$ maps $\text{span}\{\mathbf{i}, \mathbf{j}, \mathbf{k}\}$ to itself.
  Therefore, $C_q \big|_{\Im(\HH)}$ can be regaurded as an element of $\Ogroup{3}$ by identifying it with a matrix $A \in \Ogroup{3}$ so that the following commutes:
  \[\begin{tikzcd}
    {\{\mathbf{i}, \mathbf{j}, \mathbf{k}\}} &&& \Im(\HH) \\
    \\
    \\
    {\{e_1, e_2, e_3\}} &&& {\R^3}
    \arrow["{C_q |_{\Im(\HH)}}", from=1-1, to=1-4]
    \arrow["\pi"', from=1-1, to=4-1]
    \arrow["{A}"', from=4-1, to=4-4]
    \arrow["\rho", from=1-4, to=4-4]
  \end{tikzcd}\]
  where $\pi$ and $\rho$ are the obvious maps.

  (3). To show $\varphi$ is a group homomorphism, fix $q, r \in \Sp{1}$ and $v \in \Im(\HH)$.
  Then,
  \[
  \begin{aligned}
    \varphi(qr)(v) &= C_{qr} \big|_{\Im(\HH)}(v) \\
                   &= (qr)v(\overline{qr}) \\
                   &= (qr)v(\bar{r} \bar{q}) \\
                   &= q(rv\bar{r})\bar{q} \\
                   &= q \cdot C_{r} \big|_{\Im(\HH)}(v) \cdot \bar{q} \\
                   &= C_{q} \big|_{\Im(\HH)} \circ C_{r} \big|_{\Im(\HH)}(v) \\
                   &= \varphi(q) \circ \varphi(r) (v)
  \end{aligned}
  \]

  (4) The kernel of $\varphi$ is given by
  \[
  \ker{\varphi} := \{q \in \HH : \varphi(q) = \textbf{id}\}
  \]
  where $\textbf{id}$ is the identity map 
  \[\varphi(q)(v) = C_{q} \big|_{\Im(\HH)}(v) = qv\bar{q} = v\]
  for all $v$.
  Hence, if $\varphi(q) \in \ker{\varphi}$, we must have $qv = vq$, and so by Exercise 1.18, $q \in \R$, and since $q \in \Sp{1}$, $|q| = 1$, hence it must be the case that $\ker{\varphi} = \{1, -1\}$.
  Therefore, $\varphi$ is two-to-one.

\end{solution}

% Exercise 3.17
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Think of $\Sp{1} \times \Sp{1}$ as the group of pairs of unit length quarternions.
  \begin{enumerate}
    \item For every $q = (q_1, q_2) \in \Sp{1} \times \Sp{1}$ the map $F(q): \HH \to \HH$ defined by $F(q) := q_1v\bar{q_2}$ is an orthogonal linear transformation, and can thus be identified with an element of $\Ogroup{4}$ w.r.t the natural basis $\{1, \mathbf{i}, \mathbf{j}, \mathbf{k}\}$.
    \item Show that the function $F: \Sp{1} \times \Sp{1} \to \Ogroup{4}$ is a group homomorphism.
    \item Verify $\ker{F} = \{(1, 1), (-1, -1)\}$ and is therefore two-to-one.
    \item How is $F$ related to $\varphi$ from the previous exercise?
  \end{enumerate}
\end{taggedexercise}

\begin{solution}
  (1). To show $F$ is a linear transformation, let $v, w \in \HH$ and fix $q = (q_1, q_2) \in \Sp{1} \times \Sp{1}$. 
  Then,
  \[
  \begin{aligned}
    F(q)(v+w) &= q_1(v+w)\bar{q_2} \\
              &= q_1(v\bar{q_2} + w\bar{q_2}) \\
              &= q_1v\bar{q_2} + q_1w\bar{q_2} \\
              &= F(q)(v) + F(q)(w).
  \end{aligned}
  \]
  Next, fixing $\lambda \in \R$, 
  \[
  \begin{aligned}
    F(q)(\lambda v) &= q_1(\lambda v)\bar{q_2} \\
                    &= \lambda(q_1v\bar{q_2}) \\
                    &= \lambda \cdot F(q)(v)
  \end{aligned}
  \]
  hence $F(q)$ is linear.
  Next,
  \[
  \begin{aligned}
    \langle F(q)(v), F(q)(w) \rangle &= \langle q_1v\bar{q_2}, q_1w\bar{q_2} \rangle \\
                                     &= \Re(\overline{q_1v\bar{q_2}} \cdot q_1w\bar{q_2}) \\
                                     &= \Re(\overline{v\bar{q_2}}\bar{q_1}\cdot q_1w\bar{q_2}) \\
                                     &= \Re(\overline{v\bar{q_2}}(\bar{q_1}q_1)w\bar{q_2}) \\
                                     &= \Re(\overline{v\bar{q_2}}w\bar{q_2}) \\
                                     &= \Re(q_2 \bar{v}w\bar{q_2}) \\
                                     &\stackrel{*}{=} \Re(\bar{v}w) \\
                                     &= \langle v, w \rangle 
  \end{aligned}
  \]    
  where the $\stackrel{*}{=}$ is justified in the same manner as Exercise 3.15.1.
  Hence, $F(q)$ is othogonal and can be identified with an element $A \in \Ogroup{4}$ diagramatically via 
  \[\begin{tikzcd}
    {\{1, \mathbf{i}, \mathbf{j}, \mathbf{k}\}} &&& \HH \\
    \\
    \\
    {\{e_1, e_2, e_3, e_4\}} &&& {\R^4}
    \arrow["{F(q)}", from=1-1, to=1-4]
    \arrow["\pi"', from=1-1, to=4-1]
    \arrow["{A}"', from=4-1, to=4-4]
    \arrow["\rho", from=1-4, to=4-4]
  \end{tikzcd}\]
  where $\pi$ and $\rho$ are the obvious maps.

  (2). To show $F$ is a group homomorphism, fix $q, r \in \Sp{1} \times \Sp{1}$ and $v \in \HH$.
  Then, 
  \[
  \begin{aligned}
    F(qr)(v) &= F((q_1, q_2) \cdot (r_1, r_2))(v) \\
             &= F((q_1r_1, q_2r_2))(v) \\
             &= (q_1r_1)v(\overline{q_2r_2}) \\
             &= q_1(r_1v\bar{r_2})\bar{q_2} \\
             &= q_1 \cdot (F(r)(v)) \cdot\bar{q_2} \\
             &= F(q) \circ F(r) (v)
  \end{aligned}
  \]
  hence the result. 

  (3). The kernel of $F$ is given by
  \[
  \ker{F} := \{q \in \HH : F(q) = \textbf{id}\}
  \]
  where $\textbf{id}$ is the identity map 
  \[
  F(q)(v) = q_1v\bar{q_2} = v
  \]
  for all $v$. 
  Hence, $q_1v = vq_2$, and using a similar argument to Exercise 3.16.4, the only solutions are $(1,1)$ and $(-1, -1)$, hence
  \[\ker{F} = \{(1,1), (-1,-1)\}\]

  (4). $F$ is a double cover of $\Ogroup{4}$, and $\varphi$ is a double cover of $\Ogroup{3}$.
  Moreover, we get the following diagram:
  \[\begin{tikzcd}
    {\Sp{1} \times \Sp{1}} &&& \Ogroup{4} \\
    \\
    \\
    {\Sp{1}} &&& {\Ogroup{3}}
    \arrow["{F}", from=1-1, to=1-4]
    \arrow["\pi"', from=1-1, to=4-1]
    \arrow["{\varphi}"', from=4-1, to=4-4]
    \arrow["?", from=1-4, to=4-4]
  \end{tikzcd}\]
  where $?$ is an interesting map which maps both connected components of $\Ogroup{4}$ to the corresponding connected components of $\Ogroup{3}$.
\end{solution}

% Exercise 3.18
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
(Gram-Schmidt). For $m < n$, and $S = \{v_1, \dots , v_m\} \subset \K^n$ an orthonormal set, show that 
\begin{enumerate}
  \item There exist vectors $v_{m+1}, \dots , v_n$ that form $\{v_1 , \dots , v_n\}$ into an orthonormal basis of $\K^n$.
\end{enumerate}
\end{taggedexercise}

\begin{solution}
  (1). Let $v_i, v_j \in S$, and let $x$ be a vector not in the span of $S$.
  Then, let
  \[
  w = x - \sum_{i=1}^m \langle x, v_i \rangle v_i
  \]
  which is orthogonal to all the vectors in $S$, hence $S \cup \{\frac{w}{||w||}\}$ is an orthonormal set.
  Inducting gives the result.

  (2). 

\end{solution}




%==============================================================================
\chapter{The topology of matrix groups}
%==============================================================================
\section{Exercises}

%\textcolor{red}{TODO}
% Exercise 4.1
\begin{taggedexercise}[\textcolor{red}{TODO}]
Another exercise goes here.
\end{taggedexercise}

\begin{solution}
Placeholder for your solution.
\end{solution}

%==============================================================================
\chapter{Lie algebras}
%==============================================================================
\section{Exercises}

%\textcolor{red}{TODO}
% Exercise 5.1
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

% Exercise 5.2
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Verify $\alpha'(0) = A$ in the proof of Theorem 5.9.
\end{taggedexercise}

\begin{solution}
  Note that 
  \[\gamma(t) := I +tA\]
  where $A \in M_n(\K)$ has trace $0$.
  Then $\alpha(t)_{ij} = \gamma(t)_{ij}$ for all $i,j$, except when $i = 0$, in which case
  \[\alpha(t)_{0j} = \frac{\gamma(t)}{\det \gamma(t)}\]
  Therefore, 
  \[
  \begin{aligned}
    \alpha'(0)_{0j} &= \frac{d}{dt}_{t=0} \frac{\gamma(t)_{0j}}{\det \gamma(t)} \\
                    &= \frac{d}{dt}_{t=0} \gamma(t)_{0j} \cdot (\det \gamma(t))^{-1} \\
                    &= \gamma'(0)_{0j} \cdot (\det \gamma(0))^{-1} - \gamma(0)_{0j}\cdot (\det \gamma(0))^{-1} \cdot (\det \gamma'(0)) \cdot (\det \gamma(0))^{-1} \\
                    &= \gamma'(0)_{0j} - \gamma(0)_{ij}\cdot \text{trace} (\gamma '(0)) \\
                    &= \gamma'(0)_{0j}
  \end{aligned}
  \]
  hence, $\alpha '(0) = A$, since all other entries are obviously equivalent.
\end{solution}

%\textcolor{red}{TODO}
% Exercise 5.3
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

%\textcolor{red}{TODO}
% Exercise 5.4
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}


% Exercise 5.5
\begin{taggedexercise}[\textcolor{green}{Complete}]
Describe the Lie algebra of the Affine group.
\end{taggedexercise}

\begin{solution}
  Consider the path 
  \[
  \gamma(t) = \mattwo{A(t)}{0}{V(t)}{1}
  \]
  then,
  \[
  \frac{d}{dt}_{t=0} \gamma(t) = \mattwo{A'(0)}{0}{V'(0)}{0} = \mattwo{T}{0}{v}{0}
  \]
  with $T \in gl_n(\K)$ and $v \in \K^n$.
  So, the Lie algebra of the Affine group is isomorphic to $gl_n(\K) \oplus \R^n$ as a vector space.
\end{solution}

% Exercise 5.6
\begin{taggedexercise}[\textcolor{green}{Complete}]
Describe the Lie algebra of $\text{Isom}(\R^n)$.
\end{taggedexercise}

\begin{solution}
  Using the same technique as Exercise 5.6, the Lie algebra is isomorphic to $o_n(\R) \oplus \R^n$.
\end{solution}

% Exercise 5.7
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Describe the Lie algebra of $UT_n(\K)$.
\end{taggedexercise}

\begin{solution}
  Let $\gamma(t)$ be given as follows.
  First, $\gamma$ is given by the matrix
  \[(\gamma(t))_{ij} = a_{ij}(t).\]
  If $i < j$, then $a_{ij}(t) = 0$.
  If $i > j$, then $a_{ij}(0) = 0$.
  If $i = j$, then $a_{ij}(0) = 1$.
  Hence, the Lie algebra is again $UT_n(\K)$.
\end{solution}

%\textcolor{red}{TODO}
% Exercise 5.8
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Describe the Lie algebra 
\end{taggedexercise}

%\textcolor{red}{TODO}
% Exercise 5.9
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

%\textcolor{red}{TODO}
% Exercise 5.10
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

%\textcolor{red}{TODO}
% Exercise 5.11
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

%\textcolor{red}{TODO}
% Exercise 5.12
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

%\textcolor{red}{TODO}
% Exercise 5.13
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

% Exercise 5.14
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Describe the Lie algebra of $SL_n(\HH)$.
\end{taggedexercise}

%\textcolor{red}{TODO}
% Exercise 5.15
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

%\textcolor{red}{TODO}
% Exercise 5.16
\begin{taggedexercise}[\textcolor{red}{TODO}]

\end{taggedexercise}

%==============================================================================
\chapter{Matrix exponentiation}
%==============================================================================
\section{Exercises}

% \textcolor{red}{TODO}
% Exercise 6.1
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
Prove Proposition 6.5, that is, suppose that $\sum A_l$ and $\sum B_l$ converge, at least one absolutely.
Let $C_l = \sum_{k=0}^l A_kB_{l-k}$. Prove that
\[
\sum C_l = (\sum A_l)(\sum B_l)
\]
\end{taggedexercise}

\begin{solution}
\[
\begin{aligned}
  (\sum C_l)_{ij} &= (\sum_{k=0}^l A_kB_{l-k})_{ij} \\
                  &= (\sum_{k=0}^l \sum_{r=1}(A_k)_{})
\end{aligned}
\]
\end{solution}

% Exercise 6.2
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Prove that $(e^A)^* = e^{A^*}$ for all $A \in M_n(\K)$.
\end{taggedexercise}

\begin{solution}
  Using the fact that $(XY)^* = Y^*X^*$ and $(X + Y)^* = X^* + Y^*$,
  \[
  \begin{aligned}
    e^{A^*} &= \sum_{k = 0}^\infty \frac{(A^*)^k}{k!} \\
            &= \sum_{k = 0}^\infty \frac{\overbrace{A^* \cdot A^* \cdots A^*}^{k-times}}{k!} \\
            &= \sum_{k = 0}^\infty \frac{(\overbrace{A \cdot A \cdots A}^{k-times})^*}{k!} \\
            &= \sum_{k = 0}^\infty \frac{(A^k)^*}{k!} \\
            &= \left(\sum_{k = 0}^\infty \frac{(A^k)}{k!}\right)^* \\
            &= (e^A)^*
  \end{aligned}
  \]
\end{solution}

% Exercise 6.3
\begin{taggedexercise}[\textcolor{green}{Complete}]
  \begin{enumerate}
    \item Let $A = \text{diag}(a_1, \dots, a_n) \in M_n(\R)$. Calculate $e^A$ and give a simple prove that $\det(e^A) = e^{\text{trace}(A)}$ when $A$ is diagonal.
    \item Give a simple proof that $\det(e^A) = e^{\text{trace}(A)}$ when $A$ is conjugate to a diagonal matrix.
  \end{enumerate}
\end{taggedexercise}

\begin{solution}
  (1). Let $A = \text{diag}(a_1, \dots, a_n) \in M_n(\R)$.
  Then,
  \[
  \begin{aligned}
    e^{A} &= \sum_{k=0}^\infty \frac{\text{diag}(a_1, \dots, a_n)^k}{k!} \\
          &= \sum_{k=0}^\infty \frac{\text{diag}(a_1^k, \dots, a_n^k)}{k!} \\
          &= \text{diag}\left(\sum_{k=0}^\infty \frac{a_1^k}{k!}, \dots , \sum_{k=0}^\infty \frac{a_n^k}{k!} \right) \\
          &= \text{diag}(e^{a_1}, \dots , e^{a_n}).
  \end{aligned}
  \]
  Thus,
  \[
  \begin{aligned}
  \det(e^A) &= \det \left(\text{diag}(e^{a_1}, \dots , e^{a_n})\right)\\
            &= \prod_{i = 1}^{n}e^{a_i} \\
            &= e^{\sum_{j=1}^n a_j} \\
            &= e^{\tr{A}}
  \end{aligned}
  \]

  (2). Let $A \in M_n(\R)$ be conjugate to a diagonal matrix, that is there exists a diagonal matrix $D = \text{diag}(d_1, \dots, d_n)$ and an invertible matrix $P$ such that $A = PDP^{-1}$.
  Then,
  \[
  \begin{aligned}
    e^A &= \sum_{k=0}^\infty \frac{A^k}{k!} \\
        &= \sum_{k=0}^\infty \frac{(PDP^{-1})^k}{k!} \\
        &= \sum_{k=0}^\infty \frac{\overbrace{(PDP^{-1}PDP^{-1} \cdots PDP^{-1})}^{k-times}}{k!} \\
        &= \sum_{k=0}^\infty \frac{\overbrace{PD(P^{-1}P)D(P^{-1}P) \cdots (P^{-1}P)DP^{-1})}^{k-times}}{k!} \\
        &= \sum_{k=0}^\infty \frac{PD^kP^{-1}}{k!} \\
        &= P \left( \sum_{k=0}^\infty \frac{D^k}{k!} \right) P^{-1} \\
        &= P e^D P^{-1}.
  \end{aligned}
  \]
  Finishing it off:
  \[
  \begin{aligned}
    \det(e^A) &= \det(Pe^DP^{-1}) \\
              &= \det(P) \cdot \det(e^D) \cdot \det(P^{-1}) \\
              &= e^{\tr{D}} \\
              &= e^{\tr{A}}
  \end{aligned}
  \]
  where the last equality holds since similar matrices have the same trace. 
\end{solution}

% Exercise 6.4
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Let $A = \mattwo{0}{1}{-1}{0}$. Compute $e^{tA}$ for arbitrary $t \in \R$.
\end{taggedexercise}

% Needs fix! See indexing of factorial terms
\begin{solution}
  First, consider the following table:

  \begin{table}[ht]
    \centering
    \begin{tabular}{c|c}

    $k$ & $A^k$  \\ 
    \hline
    0 & $I$ \\
    1 & $A$ \\
    2 & $\mattwo{-1}{0}{0}{-1}$ \\
    3 & $\mattwo{0}{-1}{1}{0}$ \\
    4 & $I$ \\
    \end{tabular}
    \end{table}

  Hence, $A$ has periodicity $4$. 
  Therefore,
  \[
  \begin{aligned}
    e^{tA} &= \sum_{k=0}^\infty \frac{(tA)^k}{k!} \\
           &= \sum_{k=0}^\infty \frac{t^kA^k}{k!} \\
           &= \sum_{i=0}^\infty \frac{t^{4i}}{i!}I + \sum_{j=0}^\infty \frac{t^{4j + 1}}{j!}A^{4j+1} + \sum_{l=0}^\infty \frac{t^{4l + 2}}{l!}A^{4l+1} + \sum_{r=0}^\infty \frac{t^{4r + 3}}{r!}A^{4r+3} \\
           &= \sum_{i=0}^\infty \frac{t^{4i}}{i!}I + \sum_{j=0}^\infty \frac{t^{4j + 1}}{j!}A + \sum_{l=0}^\infty \frac{t^{4l + 2}}{l!}A^2 + \sum_{r=0}^\infty \frac{t^{4r + 3}}{r!}A^3 \\
           &= \sum_{i=0}^\infty \frac{(t^{4})^i}{i!}I + t\sum_{j=0}^\infty \frac{(t^{4})^j}{j!}A + t^2\sum_{l=0}^\infty \frac{(t^4)^l}{l!}A^2 + t^3\sum_{r=0}^\infty \frac{(t^4)^r}{r!}A^3 \\
           &= e^{t^4}I + te^{t^4}A + t^2e^{t^4}A^2 + t^3e^{t^4}A^3 \\
           &= e^{t^4}\left(I + tA + t^2A^2 + t^3A^3\right) \\
           &= e^{t^4} \mattwo{1-t^2}{t - t^3}{-t + t^3}{1 - t^2}
  \end{aligned}
  \]  
  Noticing that as $t \to 0$ we have $e^{tA} \to I$ is a good sanity check!
\end{solution}

% Exercise 6.5
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Can a one-parameter group ever cross itself?
\end{taggedexercise}

\begin{solution}
  No - a one-parameter group is differentiable, hence any singularity would contradict its differentiability.
  Alternatively, by Proposition 6.17, every one-parameter group is described by $\gamma(t) = e^{tA}$ for some $A \in gl_n(\K)$, and $e^{tA}$ is injective.
\end{solution}

% Exercise 6.6
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Describe all one-parameter groups of $\GL{1}{\C}$.
  Draw several in the x-y plane.
\end{taggedexercise}

% Need to draw some with tikz
\begin{solution}
  Let $z = a + b\mathbf{i} \in \GL{1}{\C}$.
  Then, any one-parameter group has the form
  \[\begin{aligned}
    \gamma_z(t) &= e^{tz} \\
                &= e^{t(a+ b\mathbf{i})} \\
                &= e^{at}e^{\mathbf{i}bt}
  \end{aligned}
  \]
  $e^{\mathbf{i}bt}$ can always be identified with a point on the unit circle, scaled by $e^{at}$.
  Hence, $\gamma_z(t)$ makes a spiral that "spirals" exponentially faster as $t$ increases that starts at $\gamma_z(0) = 1$.
  $z$ determines the initial condition and initial "spiral rate".

\end{solution}

% Exercise 6.7
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Let $G = \left\{ \mattwo{x}{y}{0}{1} \in \GL{2}{\R} : x > 0 \right\}$.
  Describe the one-parameter groups in $G$, and draw several on the $xy-$plane.
\end{taggedexercise}

% Need to draw with some tikz
\begin{solution}
  First, note that given $A \in G$,
  \[
   A = \mattwo{x}{y}{0}{1}
  \]
  \[A^2 =  \mattwo{x^2}{y(x+1)}{0}{1}\]
  and
  \[A^3 = \mattwo{x^3}{y(x^2 + x + 1)}{0}{1}\]
  It can be show inductively that
  \[
  A^k = \mattwo{x^k}{y(x^{k-1} + \cdots + 1)}{0}{1}
  \]
  and so,
  \[
  \begin{aligned}
    e^{tA} &= \sum_{k=0}^\infty \frac{t^kA^k}{k!} \\
           &= \sum_{k=0}^\infty \frac{t^k}{k!} \mattwo{x^k}{y(x^{k-1} + \cdots + 1)}{0}{1} \\
           &= \sum_{k=0}^\infty \frac{t^k}{k!} \mattwo{x^k}{y\frac{x^k-1}{x-1}}{0}{1} \\
           &= \mattwo{e^{tx}}{\frac{y}{x-1}\sum_{k=0}^\infty (tx)^k/k! - t^k/k!}{0}{e^t} \\
           &= \mattwo{e^{tx}}{\frac{y}{x-1}(e^{tx} - e^t)}{0}{e^t} \\
  \end{aligned}
  \]
  No fucking way am I drawing these.
\end{solution}

% \textcolor{red}{TODO}
% Exercise 6.8
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Visually describe the path $\gamma(t) = e^{t\mathbf{j}}$ in $Sp(1) \approxeq S^3$.
\end{taggedexercise}

\begin{solution}
  First, note that
  \begin{table}[ht]
    \centering
    \begin{tabular}{c|c}

    $k$ & $\mathbf{j}^k$  \\ 
    \hline
    0 & $1$ \\
    1 & $\mathbf{j}$ \\
    2 & $-1$ \\
    3 & $1$ \\
    \end{tabular}
    \end{table}

  hence, $\mathbf{j}$ has periodicity $3$.
  Next,
  \[
  \begin{aligned}
    \gamma(t) &= e^{t\mathbf{j}} \\
              &= \sum_{k=0}^\infty \frac{t^k}{k!} \mathbf{j}^k\\
              &= \sum_{i=0}^\infty \frac{t^i}{i!}1 + \sum_{j=0}^\infty \frac{t^j}{j!} + \sum_{l=0}^\infty \frac{t^l}{l!}
  \end{aligned}
  \]  
\end{solution}

% Exercise 6.9
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Let $A = \mattwo{a}{b}{-b}{a} \in gl_n{\R}$.
  Compute $e^A$.
\end{taggedexercise}

%To fix! Exercise 6.4 is used here, and needs to be fixed + updated here
\begin{solution}
  First, note that
  \[
    \mattwo{a}{b}{-b}{a} = \mattwo{a}{0}{0}{a} + \mattwo{0}{b}{-b}{0}
  \]
  is a decomposition of $A$ into two commuting matrices.
  Thus,
  \[
  \begin{aligned}
    e^A &= \exp{\mattwo{a}{b}{-b}{a}} \\
        &= \exp\left({\mattwo{a}{0}{0}{a} + \mattwo{0}{b}{-b}{0}}\right) \\
        &= \exp\mattwo{a}{0}{0}{a} \cdot \exp\mattwo{0}{b}{-b}{0} \\
        &= \left(\sum_{k=0}^\infty \frac{a^kI^k}{k!} \right) \cdot \left(\sum_{j=0}^\infty \frac{b^k}{j!}\exp\mattwo{0}{1}{-1}{0}^j\right) \\
        &= e^{a}I \cdot e^{b^4}\mattwo{1-b^2}{b-b^3}{-b+b^3}{1-b^2} \\
        &= e^{b^4 + a}\mattwo{1-b^2}{b-b^3}{-b+b^3}{1-b^2}
  \end{aligned}
  \]
\end{solution}

% \textcolor{red}{TODO}
% Exercise 6.10
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Repeat the previous problem with $A = \mattwo{a}{b}{b}{a}$
\end{taggedexercise}

% Exercise 6.11
\begin{taggedexercise}[\textcolor{green}{Complete}]
  When $A$ is in the Lie algebra of $UT_n(\K)$, prove that $e^A \in UT_n(\K)$.
\end{taggedexercise}

\begin{solution}
  Let $A_1, A_2 \in UT_n(\K)$ and $k$ a positive integer.
  Then clearly $A_1 + A_2$ and $R_{A_1}(A_2)$ are in $UT_n(\K)$.
  Thus, for any positive integer $k \in \Z$, $A^k \in UT_n(\K)$.
  Further, $\frac{1}{k!}A_1$ is certainly in $UT_n(\K)$.
  Hence, we can assert that 
  \[
  e^A = \sum_{k=0}^\infty \frac{A^k}{k!} \in UT_n(\K).
  \]
\end{solution}


% Exercise 6.12
\begin{taggedexercise}[\textcolor{green}{Complete}]
  When $A$ is in the Lie algebra of $\text{Isom}(\R^n)$, prove that $e^A \in \text{Isom}(\R^n)$.
\end{taggedexercise}

\begin{solution}
  Let $A_1, A_2 \in \text{Isom}(\R^n)$ and $k$ a positive integer.
  Then $A_1 + A_2$ and $R_{A_1}(A_2)$ are isometries.
  Thus, for any positive integer $k \in \Z$, $A^k$ is an isometry.
  Further, $\frac{1}{k!}A_1$ is an isometry.
  Hence, we can assert that 
  \[
  e^A = \sum_{k=0}^\infty \frac{A^k}{k!} \in \text{Isom}(\R^n).
  \]
\end{solution}


% Exercise 6.13
\begin{taggedexercise}[\textcolor{green}{Complete}]
  Describe the one-parameter groups of $\text{Trans}(\R^n)$.
\end{taggedexercise}

\begin{solution}
  Fix $A = \mattwo{I}{0}{X}{1} \in \text{Trans}(\R^n)$.
  Then it is clear that 
  \[A^k = \mattwo{I}{0}{X}{1}^k = \mattwo{I}{0}{kX}{1}\]
  hence,
  \[\begin{aligned}
    e^{tA} &= \sum_{k=0}^\infty \frac{(tA)^k}{k!} \\
        &= \sum_{k=0}^\infty \frac{t^k}{k!}\mattwo{I}{0}{kX}{1} \\
        &= e^t\mattwo{I}{0}{tX}{1}.
  \end{aligned}\]
\end{solution}

% \textcolor{red}{TODO}
% Exercise 6.14
\begin{taggedexercise}[\textcolor{red}{TODO}]
  
\end{taggedexercise}

%==============================================================================
\chapter{Matrix groups are manifolds}
%==============================================================================
\section{Exercises}

\begin{taggedexercise}[\textcolor{green}{Complete}]
  Define the $\textbf{stereographic projection}$ as 
  \[
  f: S^2 - \{0,0,1\} \to \R^2
  \]
  via shooting a lazer from the north pole of $S^2$; the lazer hits a point $p = (x,y,z)$ on $S^2$ and a subsequent point on $R^2$ (given by the plane $z = -1$), identifying $p \in S^2 - \{0,0,1\}$ with $f(p) \in \R^2$.
  \begin{enumerate}
    \item Show that \[f(x,y,z) = \frac{2}{1-z}(x,y)\]
    \item Find a formula for $f^{-1}$
    \item Find a formula \[g: S^2 - \{0,0,-1\} \to \R^2\] defined analgously to $f$, but the plane of intersection is $z=1$.
    \item Find an explicit formula for the composition \[g \circ f^{-1} : \R^2 - \{0,0\} \to \R^2 - \{(0,0)\}\]
  \end{enumerate}
\end{taggedexercise}

\begin{solution}
  (1). Fix the following lines:
  \begin{enumerate}
    \item $\ell_1$ between $(0,0,-1)$ and $(0,0,1)$
    \item $\ell_2$ between $(0,0,1)$ and $f(p) = f(x,y,z)$
    \item $\ell_3$ between $(0,0,-1)$ and $f(p) = f(x,y,z)$
    \item $\ell_4$ between $(0,0,1)$ and $(0,0,1-z)$
    \item $\ell_5$ between $(0,0,1)$ and $p = (x,y,z)$
    \item $\ell_6$ between $(0,0,1-z)$ and $p = (x,y,z)$
  \end{enumerate}
  Its clear that $T_1 = \{\ell_1, \ell_2, \ell_3\}$ and $T_2 = \{\ell_4, \ell_5, \ell_6\}$ are similar.
  Morever, $\ell_1 = 2$ and $\ell_4 = 1-z$.
  Therefore,
  \[
  \frac{1-z}{2} = \frac{(x,y)}{f(x,y,z)} \implies f(x,y,z) = \frac{2}{1-z}(x,y).
  \]
 
  (2). Let $f(x,y,z) = (u, v) \in \R^2$.
  Then, parameterize the line from $(0,0,1)$ to $(u,v)$ with
  \[L(t) = (0, 0, 1) + t(u, v, -2) = (tu, tv, 1-2t)\]
  where $t \in [0, 1]$.
  We want to know when $L(t)$ intersects the sphere, as in when 
  \[\begin{aligned}
    (tu)^2 + (tv)^2 + (1-2t)^2 = 1 &\implies (u^2 + v^2)t^2 -4t + 4t^2= 0 \\
                                   &\implies (u^2 + v^2 + 4)t^2 -4t= 0 \\
                                   &\implies t\left[(u^2 + v^2 + 4)t -4 \right]= 0 \\
  \end{aligned}
  \]
  where $t = \frac{4}{u^2 + v^2 + 4}$ is clearly the relevant solution.
  Therefore, 
  \[
  f^{-1}(u, v) = (tu, tv, 1-2t) = \left(\frac{4u}{u^2 + v^2 + 4},\frac{4v}{u^2 + v^2 + 4},1 - \frac{8}{u^2 + v^2 + 4} \right)
  \]
  
  (3). We can recover step (1) by mapping $1-z \to z-1$, hence we get 
  \[g(x,y,z) = \frac{2}{z-1}(x,y)\] 

  (4). Let $c = \frac{4}{u^2 + v^2 + 4}$.
  Composition gives
  \[\begin{aligned}
    g \circ f^{-1}(u, v) &= g\left(cu,cv,1 - 2c\right) \\
                         &= \frac{2}{1-1-2c}(cu, cv) \\
                         &= -(u,v)
  \end{aligned}\]
  which is super chill!

\end{solution}

\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Prove that $S^n \subset \R^{n+1}$ is an $n-$dimensional manifold.
\end{taggedexercise}
\begin{solution}
  Define 
  \[V = \{(x_1, \dots, x_{n+1}) \in S^n : x_{n+1} >0\}\]
  which is a neigbourhood of $(0, 0, \dots, 1) \in S^n$.
  Next, define
  \[U = \{(a_1, \dots, a_n) : a_1^2 + \cdots + a_n^2 < 1\}\]
  and define
  \[\varphi : U \to V\]
  \[\varphi(a_1, \dots, a_n) := (a_1, a_2, \dots , a_n, \sqrt{1 - a_n^2 - \cdots - a_1^2})\]
\end{solution}

%==============================================================================
\chapter{The Lie bracket}
%==============================================================================
\section{Exercises}

% Exercise 8.1
\begin{taggedexercise}[\textcolor{green}{Complete}]
Prove that $\SO{3}$ is not abelian in two ways:
\begin{enumerate}
  \item Find two elements in $\so{3}$ that do not commute.
  \item Find two elements in $\SO{3}$ that do not commute.
\end{enumerate}
Which is easier? 
Prove that $\SO{n}$ is not abelian for $n > 2$.
\end{taggedexercise}

\begin{solution}
  (1). Consider the basis given for $\so{3}$ in Theorem 5.12, that is
  \[\so{3} = \text{span} \left\{
    E_1 = \begin{bmatrix}
      0 & 0 & 0 \\
      0 & 0 & -1 \\
      0 & 1 & 0
      \end{bmatrix}, 
    E_2 = \begin{bmatrix}
      0 & 0 & 1 \\
      0 & 0 & 0 \\
      -1 & 0 & 0
      \end{bmatrix},
    E_3 = \begin{bmatrix}
      0 & -1 & 0 \\
      1 & 0 & 0 \\
      0 & 0 & 0
      \end{bmatrix} \right\}\]
  then we have 
  \[[E_1, E_2] = E_3\]
  hence $E_1$ and $E_2$ do not commute.

  (2). Let
  \[
    R_z(\theta) =
    \begin{bmatrix}
    \cos\theta & -\sin\theta & 0 \\
    \sin\theta & \cos\theta & 0 \\
    0 & 0 & 1
    \end{bmatrix}
  \]
  and 
  \[
    R_x(\phi) =
    \begin{bmatrix}
    1 & 0 & 0 \\
    0 & \cos\phi & -\sin\phi \\
    0 & \sin\phi & \cos\phi
    \end{bmatrix}
  \]
  then 
  \[
    R_z(\theta) R_x(\phi) =
    \begin{bmatrix}
    \cos\theta & -\sin\theta\cos\phi & \sin\theta\sin\phi \\
    \sin\theta & \cos\theta\cos\phi & -\cos\theta\sin\phi \\
    0 & \sin\phi & \cos\phi
    \end{bmatrix}
  \]
  but 
  \[
    R_x(\phi) R_z(\theta) =
    \begin{bmatrix}
    \cos\theta & -\sin\theta & 0 \\
    \sin\theta\cos\phi & \cos\theta\cos\phi & -\sin\phi \\
    \sin\theta\sin\phi & \cos\theta\sin\phi & \cos\phi
    \end{bmatrix}
  \]
  hence $\SO(3)$ is not abelian.

  to prove $SO(n)$ is not abelian for $n > 2$, consider the basis $\{E_1, \dots E_n\}$ as described in Theorem 5.2.
  Then if $n >2$, we have that 
  \[[E_i, E_j] = E_k\]
  for some $i \neq j \neq k$, hence $\so{n}$ is not abelian, and so $SO(3)$ is not abelian.

\end{solution}

% Exercise 8.2
\begin{taggedexercise}[\textcolor{red}{Complete}]
  Let $G_1, G_2$ be matrix groups with Lie algebras $\mathfrak{g}_1, \mathfrak{g_2}$.
  Suppose that $f: G_1 \to G_2$ is a smooth homomorphism.
  If $df_I : \mathfrak{g}_1 \to \mathfrak{g}_2$ is bijective, prove that $df_g : T_gG_1 \to T_{f(g)}G_2$ is bijective for all $g \in G_1$.
\end{taggedexercise}

\begin{solution}
  Given a group $G$ with $g \in G$, let $L_g : G \to G$ be the left-multiplication map $L_g(G) := gG$.
  Then $L_g$ is a group automomorphism.
  It is straightforward to show that
  \[df_g = d\left(L_{f(g)}\right) \circ df_I \circ d\left( L^{-1}_g \right).\]
  where the composition
  \[\begin{tikzcd}
	{T_gG_1} && {\mathfrak{g}_1} && {\mathfrak{g}_1} && {T_{f(g)}G_2}
	\arrow["{d(L^{-1}_g)}", from=1-1, to=1-3]
	\arrow["{df_I}", from=1-3, to=1-5]
	\arrow["{d(L_{f(g)})}", from=1-5, to=1-7]
\end{tikzcd}\]
  is a composition of linear maps, and hence linear, and hence bijective.

\end{solution}

% Exercise 8.3
\begin{taggedexercise}[\textcolor{yellow}{WIP}]
  Define $d: \Sp{1} \to \Sp{1} \times \Sp{1}$ as $d(a) := (a, a)$.
  Explicitly describe the function $\iota : \SO{3} \to \SO{4}$ that makes the following diagram commute:
  \[\begin{tikzcd}
	{\Sp{1}} && {\Sp{1} \times \Sp{1}} \\
	\\
	{\SO{3}} && {\SO{4}}
	\arrow["d", from=1-1, to=1-3]
	\arrow["{\text{Ad}}"', from=1-1, to=3-1]
	\arrow["F", from=1-3, to=3-3]
	\arrow["\iota"', from=3-1, to=3-3]
\end{tikzcd}\]
\end{taggedexercise}

\begin{solution}
  Fix $(a,a) \in \Sp{1} \times \Sp{1}$.
  If $v \in \HH$ is purely imaginary, then $F$ is exactly the action $\text{Ad}_a$.
  If $v$ is real, then $F(a,a)(v) = v$, hence the real axis is fixed pointwise when viewing $F$ as acting on $\R^4$.
  Therefore, given $M \in \SO{3}$ where $M$ coincides with the action of $\text{Ad}_a$, $\iota$ is the inclusion 
  \[\iota(M) = \mattwo{1}{0}{0}{M}\]



\end{solution}

% Exercise 8.4
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Another exercise goes here.
\end{taggedexercise}

% Exercise 8.5
\begin{taggedexercise}[\textcolor{red}{TODO}]
\end{taggedexercise}

\begin{solution}
\end{solution}

% Exercise 8.6
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Another exercise goes here.
\end{taggedexercise}

% Exercise 8.7
\begin{taggedexercise}[\textcolor{red}{TODO}]
  Another exercise goes here.
\end{taggedexercise}

%==============================================================================
\chapter{Maximal tori}
%==============================================================================
\section{Exercises}

\begin{exercise}
Another exercise goes here.
\end{exercise}

\begin{solution}
Placeholder for your solution.
\end{solution}

%==============================================================================
\chapter{Homogeneous manifolds}
%==============================================================================
\section{Exercises}

\begin{exercise}
Another exercise goes here.
\end{exercise}

\begin{solution}
Placeholder for your solution.
\end{solution}

%==============================================================================
\chapter{Roots}
%==============================================================================
\section{Exercises}

\begin{exercise}
Another exercise goes here.
\end{exercise}

\begin{solution}
Placeholder for your solution.
\end{solution}

%==============================================================================
\end{document}
